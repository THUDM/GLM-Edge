# GLM-Edge

Read this in [English](README_en.md)

åœ¨ <a href="https://huggingface.co/spaces/THUDM-HF-SPACE/GLM-Edge-1.5B-Chat-Space" target="_blank"> ğŸ¤— è¿™é‡Œ</a> ä½“éªŒ GLM-Edge-1.5B-Chat ç«¯ä¾§æ¨¡å‹

åœ¨ <a href="https://huggingface.co/spaces/THUDM-HF-SPACE/GLM-Edge-V-5B-Space" target="_blank"> ğŸ¤— è¿™é‡Œ</a> ä½“éªŒ GLM-Edge-V-5B ç«¯ä¾§æ¨¡å‹


## æ¨¡å‹ä»‹ç»

**GLM-Edge** ç³»åˆ—æ˜¯æˆ‘ä»¬åœ¨é¢å‘ç«¯ä¾§çœŸå®è½åœ°ä½¿ç”¨çš„åœºæ™¯ä¸‹çš„ä¸€æ¬¡å°è¯•ï¼Œç”±ä¸¤ç§å°ºå¯¸çš„å¤§è¯­è¨€å¯¹è¯æ¨¡å‹å’Œå¤šæ¨¡æ€ç†è§£æ¨¡å‹ç»„æˆï¼ˆ
`GLM-Edge-1.5B-Chat`ï¼Œ`GLM-Edge-4B-Chat`ï¼Œ`GLM-Edge-V-2B`ï¼Œ`GLM-Edge-V-5B`ï¼‰ã€‚å…¶ä¸­ï¼Œ`1.5B / 2B`æ¨¡å‹ä¸»è¦é¢å‘æ‰‹æœºã€è½¦æœºç­‰å¹³å°ï¼Œ
`4B / 5B` æ¨¡å‹ä¸»è¦é¢å‘PCç­‰å¹³å°ã€‚

åŸºäºGLM-4ç³»åˆ—çš„æŠ€æœ¯ç§¯ç´¯ï¼Œæˆ‘ä»¬é’ˆå¯¹ç«¯ä¾§å®é™…éƒ¨ç½²æƒ…å†µï¼Œå¯¹æ¨¡å‹ç»“æ„å’Œå°ºå¯¸åšäº†é’ˆå¯¹æ€§çš„è°ƒæ•´ï¼Œä»¥æ±‚åœ¨æ¨¡å‹è¡¨ç°ã€å®æœºæ¨ç†æ•ˆæœå’Œè½åœ°ä¾¿åˆ©åº¦ä¹‹é—´è¾¾åˆ°å¹³è¡¡ã€‚åŒæ—¶ï¼Œé€šè¿‡ä¸ä¼™ä¼´ä¼ä¸šçš„æ·±å…¥åˆä½œå’Œåœ¨æ¨ç†ä¼˜åŒ–ä¸Šçš„ä¸æ‡ˆåŠªåŠ›ï¼Œåœ¨ä¸€äº›ç«¯ä¾§å¹³å°ä¸Šï¼ŒGLM-Edgeç³»åˆ—æ¨¡å‹èƒ½ä»¥æå¿«çš„é€Ÿåº¦è¿è¡Œã€‚

ä¾‹å¦‚ï¼Œåœ¨é«˜é€šéªé¾™8 Eliteå¹³å°ä¸Šï¼Œå€ŸåŠ©å…¶å¼ºå¤§çš„NPUç®—åŠ›ï¼ŒGLM-Edgeé€šè¿‡æ··åˆé‡åŒ–æ–¹æ¡ˆï¼Œ1.5Bå¯¹è¯æ¨¡å‹ã€2Bå¤šæ¨¡æ€æ¨¡å‹èƒ½å®ç°æ¯ç§’60
tokensä»¥ä¸Šçš„è§£ç é€Ÿåº¦ã€‚åœ¨åº”ç”¨æŠ•æœºé‡‡æ ·æŠ€æœ¯ä¹‹åï¼Œä¸¤ä¸ªæ¨¡å‹èƒ½ä»¥å³°å€¼æ¯ç§’100 tokensä»¥ä¸Šçš„è§£ç é€Ÿåº¦è¿è¡Œã€‚è¿™äº›æ¨ç†æ–¹æ¡ˆä¼šç”±æˆ‘ä»¬æˆ–åˆä½œä¼™ä¼´åç»­æ”¾å‡ºã€‚

æ¨¡å‹ä¸‹è½½åœ°å€ï¼š

|       Model        |                                                                                                     HuggingFace Model                                                                                                      |                                                                                                                GGUF Model                                                                                                                 |
|:------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| GLM-Edge-1.5B-Chat | [ğŸ¤— Huggingface](https://huggingface.co/THUDM/glm-edge-1.5b-chat)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/glm-edge-1.5b-chat) <br> [ğŸŸ£ WiseModel](https://wisemodel.cn/models/ZhipuAI/glm-edge-1.5b-chat) | [ğŸ¤— Huggingface](https://huggingface.co/THUDM/glm-edge-1.5b-chat-gguf)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/glm-edge-1.5b-chat-gguf) <br> [ğŸŸ£ WiseModel](https://wisemodel.cn/models/ZhipuAI/glm-edge-1.5b-chat-gguf) |
|  GLM-Edge-4B-Chat  | [ğŸ¤— Huggingface](https://huggingface.co/THUDM/glm-edge-4b-chat)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/glm-edge-4b-chat)      <br> [ğŸŸ£ WiseModel](https://wisemodel.cn/models/ZhipuAI/glm-edge-4b-chat)  |    [ğŸ¤— Huggingface](https://huggingface.co/THUDM/glm-edge-4b-chat-gguf)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/glm-edge-4b-chat-gguf) <br> [ğŸŸ£ WiseModel](https://wisemodel.cn/models/ZhipuAI/glm-edge-4b-chat-gguf)    |
|   GLM-Edge-V-2B    |        [ğŸ¤— Huggingface](https://huggingface.co/THUDM/glm-edge-v-2b)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/glm-edge-v-2b) <br> [ğŸŸ£ WiseModel](https://wisemodel.cn/models/ZhipuAI/glm-edge-v-2b)         |        [ğŸ¤— Huggingface](https://huggingface.co/THUDM/glm-edge-v-2b-gguf)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/glm-edge-v-2b-gguf) <br> [ğŸŸ£ WiseModel](https://wisemodel.cn/models/ZhipuAI/glm-edge-v-2b-gguf)         |
|   GLM-Edge-V-5B    |   [ğŸ¤— Huggingface](https://huggingface.co/THUDM/glm-edge-v-5b)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/glm-edge-v-5b)           <br> [ğŸŸ£ WiseModel](https://wisemodel.cn/models/ZhipuAI/glm-edge-v-5b)    |        [ğŸ¤— Huggingface](https://huggingface.co/THUDM/glm-edge-v-5b-gguf)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/glm-edge-v-5b-gguf) <br> [ğŸŸ£ WiseModel](https://wisemodel.cn/models/ZhipuAI/glm-edge-v-5b-gguf)         |

## å®æœºè¿è¡Œæ•°æ®

æ•°æ®é‡‡é›†æ—¥æˆªæ­¢åˆ°2024å¹´11æœˆ28æ—¥ã€‚æˆ‘ä»¬è¿˜åœ¨ç§¯æåœ°ä¸åˆä½œä¼™ä¼´ä»¬ä¸€é“ä¼˜åŒ–è¿™äº›æ€§èƒ½ã€‚

### é«˜é€š

| æ¨¡å‹                 | ä»»åŠ¡                     | é‡åŒ–æ–¹æ¡ˆ | æ¡†æ¶  | 1st token latency (ms) | Token Rate (tokens/s) | Peak Memory Footprint (GB) |
|--------------------|------------------------|------|-----|------------------------|-----------------------|----------------------------|
| GLM-Edge-4B-Chat   | (input/output=512/128) | INT4 | QNN | 260                    | 65                    | 2.9                        |
| GLM-Edge-1.5B-Chat | (input/output=512/128) | INT4 | QNN | 660                    | 24                    | 1.2                        |

* åœ¨é«˜é€š8 Eliteï¼ˆGen4ï¼‰å¹³å°ä¸Šæµ‹è¯•ï¼Œæ¨¡å‹å…¨éƒ¨è¿è¡Œåœ¨NPUä¸Š
* å¦‚è¿è¡ŒVæ¨¡å‹ï¼Œå¦å¤–éœ€è¦å•å›¾890msçš„å¤„ç†æ—¶é—´å’Œçº¦660Mçš„é¢å¤–å†…å­˜
* ä½¿ç”¨æŠ•æœºè§£ç æ–¹æ¡ˆæ—¶ï¼ŒToken Rateè¿˜æœ‰æœ€é«˜50%çš„æå‡

### Intel

| æ¨¡å‹                 | ä»»åŠ¡                                   | é‡åŒ–æ–¹æ¡ˆ | æ¡†æ¶       | 1st token latency (ms) | Token Rate (tokens/s) | Peak Memory Footprint (GB) |
|--------------------|--------------------------------------|------|----------|------------------------|-----------------------|----------------------------|
| GLM-Edge-4B-Chat   | (input/output=1024/128)              | INT4 | OPENVINO | 541.2                  | 27                    | 3.9                        |
| GLM-Edge-1.5B-Chat | (input/output=1024/128)              | INT4 | OPENVINO | 228.2                  | 63                    | 2.3                        |
| GLM-Edge-V-2B      | Single image understanding (672x672) | INT4 | OPENVINO | 362.1                  | 70                    | 3.4                        |

* åœ¨Intel LNL 288V (ARC 140V 8X@2.05GHz) å¹³å°ä¸Šæµ‹è¯•ã€‚
* å¦‚è¿è¡ŒVæ¨¡å‹ï¼Œå¦å¤–éœ€è¦å•å›¾1.7sçš„å¤„ç†æ—¶é—´å’Œçº¦2Gçš„é¢å¤–å†…å­˜ã€‚

## å®‰è£…ä¾èµ–

è¯·ç¡®ä¿ä½ çš„Pythonç‰ˆæœ¬ä¸º`3.10`æˆ–æ›´é«˜ç‰ˆæœ¬ã€‚å¹¶æŒ‰ç…§å¦‚ä¸‹æ–¹å¼å®‰è£…ä¾èµ–ï¼Œå®‰è£…ä»¥ä¸‹ä¾èµ–èƒ½ç¡®ä¿æ­£ç¡®è¿è¡Œæœ¬ä»“åº“çš„æ‰€æœ‰ä»£ç ã€‚

```shell
pip install -r requirements.txt
```

## æ¨¡å‹æ¨ç†

### Transformers / OpenVINO / vLLM Demo

æˆ‘ä»¬æä¾›äº† vLLM, OpenVINO å’Œ transformers ä¸‰ç§åç«¯æ¨ç†æ–¹å¼,ä½ å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥è¿è¡Œæ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªå‘½ä»¤è¡Œäº¤äº’ä»£ç ã€‚

```shell
python cli_demo.py --backend transformers --model_path THUDM/glm-edge-1.5b-chat --precision bfloat16
python cli_demo.py --backend vllm --model_path THUDM/glm-edge-1.5b-chat --precision bfloat16
python cli_demo.py --backend ov --model_path THUDM/glm-edge-1.5b-chat-ov  --precision int4
```

> æ³¨æ„ï¼š
>
> OpenVINO ç‰ˆæœ¬æ¨¡å‹éœ€è¦è¿›è¡Œè½¬æ¢ï¼Œè¯·å‰å¾€ [è¿™é‡Œ](inference/ov_convert) è¿è¡Œè½¬æ¢ä»£ç ã€‚
>
> ```python convert_chat.py --model_path  THUDM/glm-edge-1.5b-chat --precision int4 ``` è½¬æ¢å¯¹è¯æ¨¡å‹ã€‚
>
> ```python convert.py --model_path  THUDM/glm-edge-v-2b --precision int4``` è½¬æ¢è§†è§‰ç†è§£æ¨¡å‹ã€‚
>
> ä½ ä¹Ÿå¯ä»¥åœ¨ [è¿™é‡Œ](https://github.com/openvino-dev-samples/glm-edge.openvino) æŸ¥çœ‹åŸå§‹çš„è½¬æ¢ä»£ç ã€‚
>
> vLLM ç‰ˆæœ¬æ¨¡å‹éœ€è¦ä» [è¿™é‡Œ](https://github.com/sixsixcoder/vllm/tree/glm-4) æºä»£ç  å®‰è£… vLLM ä»¥æ­£å¸¸è¿è¡Œã€‚

å¦‚æœä½ æƒ³ä½¿ç”¨ glm-edge-v ç³»åˆ—æ¨¡å‹ï¼Œä½ å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤è¡Œäº¤äº’ä»£ç 

```shell
python cli_demo_vision.py  --backend transformers --model_path THUDM/glm-edge-v-2b --precision bfloat16
python cli_demo.py --backend ov --model_path THUDM/glm-edge-1.5b-chat-ov  --precision int4
```

ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ Gradio å¯åŠ¨ WebUIã€‚

```shell
python cli_demo.py --backend transformers --model_path THUDM/glm-edge-1.5b-chat --precision bfloat16
python cli_demo.py --backend vllm --model_path THUDM/glm-edge-1.5b-chat --precision int4 # For Int4 Inference
```

### XInference

å¦‚æœä½ ä½¿ç”¨ XInference è¿›è¡Œæ¨ç†ï¼Œä½ å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥è¿è¡Œæ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªå‘½ä»¤è¡Œäº¤äº’ä»£ç ã€‚

```python
xinference
launch - -model - engine
Transformers - -model - name
glm - edge - v - -size - in -billions
2 - -model - format
pytorch - -quantization
none
```

ä½¿ç”¨ OpenAI APIè¿›è¡Œæ¨ç†:

```python
import openai

client = openai.Client(
    api_key="cannot be empty",
    base_url="http://<XINFERENCE_HOST>:<XINFERENCE_PORT>/v1"
)
output = client.chat.completions.create(
    model="glm-edge-v",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    'type': 'text',
                    'text': 'describe this image',
                },
                {
                    'type': 'image_url',
                    'image_url': {
                        "url": "img.png",
                    }
                },
            ],
        }
    ],
    max_tokens=512,
    temperature=0.7
)

print(output)
```

## å¾®è°ƒæ¨¡å‹

æˆ‘ä»¬æä¾›äº†å¾®è°ƒæ¨¡å‹çš„ä»£ç ï¼Œè¯·å‚è€ƒ [å¾®è°ƒæ•™ç¨‹](finetune/README.md)ã€‚

## åè®®

æœ¬ github ä»“åº“ä»£ç çš„ä½¿ç”¨ [Apache2.0 LICENSE](LICENSE)ã€‚

æ¨¡å‹æƒé‡çš„ä½¿ç”¨è¯·éµå¾ª [Model License](MODEL_LICENSE)ã€‚
