# GLM-Edge

Read this in [English](README_en.md)

## é¡¹ç›®æ›´æ–°

- ğŸ”¥ğŸ”¥ **News**: ```2024/11/30```: æˆ‘ä»¬å‘å¸ƒ `GLM-Edge` æ¨¡å‹ã€‚å…±è®¡`glm-edge-1.5b-chat`, `glm-edge-4b-chat`, `glm-edge-v-2b`,
  `glm-edge-v-5b` å››ä¸ªæ¨¡å‹ã€‚å¹¶å‘å¸ƒäº†åŸºç¡€çš„æ¨ç†ä»£ç ã€‚

## æ¨¡å‹ä»‹ç»

GLM-Edge ç³»åˆ—æ¨¡å‹æ˜¯é’ˆå¯¹ç«¯ä¾§é¢†åŸŸè®¾è®¡çš„æ¨¡å‹ã€‚ æˆ‘ä»¬å‘å¸ƒäº†`glm-edge-1.5b-chat`, `glm-edge-4b-chat`, `glm-edge-v-2b`,
`glm-edge-v-5b` å››ä¸ªæ¨¡å‹ã€‚

## å®‰è£…ä¾èµ–

è¯·ç¡®ä¿ä½ çš„Pythonç‰ˆæœ¬ä¸º`3.10`æˆ–æ›´é«˜ç‰ˆæœ¬ã€‚å¹¶æŒ‰ç…§å¦‚ä¸‹æ–¹å¼å®‰è£…ä¾èµ–ï¼Œå®‰è£…ä»¥ä¸‹ä¾èµ–èƒ½ç¡®ä¿æ­£ç¡®è¿è¡Œæœ¬ä»“åº“çš„æ‰€æœ‰ä»£ç ã€‚

```shell
pip install -r requirements.txt
```

## æ¨¡å‹æ¨ç†

### Transformers / OpenVINO / vLLM Demo

æˆ‘ä»¬æä¾›äº† vLLM, OpenVINO å’Œ transformers ä¸‰ç§åç«¯æ¨ç†æ–¹å¼,ä½ å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥è¿è¡Œæ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªå‘½ä»¤è¡Œäº¤äº’ä»£ç ã€‚

```shell
python cli_demo.py --backend transformers --model_path THUDM/glm-edge-1.5b-chat --precision bfloat16
python cli_demo.py --backend vllm --model_path THUDM/glm-edge-1.5b-chat --precision bfloat16
python cli_demo.py --backend ov --model_path THUDM/glm-edge-1.5b-chat-ov  --precision int4
```

> æ³¨æ„ï¼š
>
> OpenVINO ç‰ˆæœ¬æ¨¡å‹éœ€è¦è¿›è¡Œè½¬æ¢ï¼Œè¯·å‰å¾€ [è¿™é‡Œ](inference/ov_convert) è¿è¡Œè½¬æ¢ä»£ç ã€‚
> 
> ```python convert_chat.py --model_path  THUDM/glm-edge-1.5b-chat --precision int4 ``` è½¬æ¢å¯¹è¯æ¨¡å‹ã€‚
> 
> ```python convert.py --model_path  THUDM/glm-edge-v-2b --precision int4``` è½¬æ¢è§†è§‰ç†è§£æ¨¡å‹ã€‚
> 
> ä½ ä¹Ÿå¯ä»¥åœ¨ [è¿™é‡Œ](https://github.com/openvino-dev-samples/glm-edge.openvino) æŸ¥çœ‹åŸå§‹çš„è½¬æ¢ä»£ç ã€‚
> 
> vLLM ç‰ˆæœ¬æ¨¡å‹éœ€è¦ä» [è¿™é‡Œ]() æºä»£ç  å®‰è£… vLLM ä»¥æ­£å¸¸è¿è¡Œã€‚

å¦‚æœä½ æƒ³ä½¿ç”¨ glm-edge-v ç³»åˆ—æ¨¡å‹ï¼Œä½ å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤è¡Œäº¤äº’ä»£ç 

```shell
python cli_demo_vision.py  --backend transformers --model_path THUDM/glm-edge-v-2b --precision bfloat16
python cli_demo.py --backend ov --model_path THUDM/glm-edge-1.5b-chat-ov  --precision int4
```

ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ Gradio å¯åŠ¨ WebUIã€‚

```shell
python cli_demo.py --backend transformers --model_path THUDM/glm-edge-1.5b-chat --precision bfloat16
python cli_demo.py --backend vllm --model_path THUDM/glm-edge-1.5b-chat --precision int4 # For Int4 Inference
```


### XInference

å¦‚æœä½ ä½¿ç”¨ XInference è¿›è¡Œæ¨ç†ï¼Œä½ å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥è¿è¡Œæ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªå‘½ä»¤è¡Œäº¤äº’ä»£ç ã€‚

```shell
```

## å¾®è°ƒæ¨¡å‹

æˆ‘ä»¬æä¾›äº†å¾®è°ƒæ¨¡å‹çš„ä»£ç ï¼Œè¯·å‚è€ƒ [å¾®è°ƒæ•™ç¨‹](finetune/README.md)ã€‚

## åè®®

æœ¬ github ä»“åº“ä»£ç çš„ä½¿ç”¨ [Apache2.0 LICENSE](LICENSE)ã€‚

æ¨¡å‹æƒé‡çš„ä½¿ç”¨è¯·éµå¾ª [Model License](MODEL_LICENSE)ã€‚
